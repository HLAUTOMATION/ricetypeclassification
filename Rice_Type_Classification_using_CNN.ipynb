{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46029b0",
   "metadata": {
    "id": "a46029b0"
   },
   "source": [
    "# **Rice Type Classification**\n",
    "\n",
    "----------------------\n",
    "## **Context**\n",
    "----------------------\n",
    "\n",
    "Rice forms the staple ingredient for meals across multiple countries all over the world. Rice provides 21% of global human per capita energy and 15% of per capita protein. For several Asian nations, rice is also very important from a business perspective. India had the highest export volume of rice worldwide, at 18.75 million metric tons as of 2021/2022.  It exports non-Basmati rice to African countries and Basmati to the Middle East. Vietnam was the second-largest rice exporter, with about 6.5 million metric tons of rice worldwide in that year.\n",
    "\n",
    "Deep learning algorithms have recently seen numerous applications in the field of agriculture, specifically in crop identification. Convolutional Neural Networks (CNN) can be utilized to identify the different rice types, as classifying rice into its true type becomes a very necessary step in agricultural export businesses globally.\n",
    "\n",
    "---------------------\n",
    "## **Objective**\n",
    "---------------------\n",
    "The project aims to build a Neural Network to differentiate among 5 different rice types, namely Arborio, Basmati, Ipsala, Jasmine, and Karacadag.\n",
    "\n",
    "----------------------\n",
    "## **Dataset**\n",
    "----------------------\n",
    "The dataset is a folder consisting of close to 75000 images split into 3 folders namely, train, validation, and test. Each of these three folders has 5 sub-folders that are named after the 5 types of rice we are going to be studying here, i.e., Arborio, Basmati, Ipsala, Jasmine, and Karacadag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b73ee",
   "metadata": {
    "id": "218b73ee"
   },
   "source": [
    "## **Importing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815bfd4d",
   "metadata": {
    "id": "815bfd4d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "\n",
    "# Importing Deep Learning Libraries\n",
    "\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, LeakyReLU, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70351f0",
   "metadata": {
    "id": "d70351f0"
   },
   "source": [
    "We will be using **Google Colab** to run this notebook. Please don't run the notebook on Jupyter in order to avoid errors due to uninstalled libraries. For a better understanding on how Google Colab works, please refer to the 'Getting Started with Google Colab' module under the 'Getting Started with Deep Learning' section in the Deep Learning week.\n",
    "\n",
    "First, let's **import the data** so that Colab can access the dataset. One way to load the data in Colab is by uploading the dataset from your Google drive. Please make sure that you have downloaded the dataset file from your Olympus in zipped format and that you have uploaded it to your Google Drive in the same format. Once you run the cell, it will ask you permission to link your drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nLCZ_whQtPZz",
   "metadata": {
    "id": "nLCZ_whQtPZz"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'termios'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Mounting the drive\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      4\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\colab\\__init__.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _installation_commands\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _shell_customizations\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _system_commands\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _tensorflow_magics\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auth\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\colab\\_system_commands.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlocale\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpty\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mselect\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msignal\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\pty.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtty\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# names imported directly for test mocking purposes\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m close, waitpid\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\tty.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Terminal utilities.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Steen Lumholt.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtermios\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetcbreak\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Indexes for termios list.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'termios'"
     ]
    }
   ],
   "source": [
    "# Mounting the drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6lPdmNBjMRTs",
   "metadata": {
    "id": "6lPdmNBjMRTs"
   },
   "outputs": [],
   "source": [
    "# Storing the path of the data file from the Google drive\n",
    "#path = '/content/drive/MyDrive/Rice_Image_Dataset.zip'\n",
    "path = 'C:/Users/sonyx/Downloads/Mit/5_deeplearning/live2_CNNs/ricetype/Rice_Image_Dataset.zip'\n",
    "\n",
    "# The data is provided as a zip file so we need to extract the files from the zip file\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94c810",
   "metadata": {
    "id": "4c94c810"
   },
   "outputs": [],
   "source": [
    "picture_size = 48\n",
    "folder_path = \"Rice_Image_Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca512e",
   "metadata": {
    "id": "59ca512e"
   },
   "source": [
    "## **Visualizing the Rice Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yqNRw5EQYj_1",
   "metadata": {
    "id": "yqNRw5EQYj_1"
   },
   "source": [
    "Let's visualize each kind of rice separately and observe their physical appearances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ebd0db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "14ebd0db",
    "outputId": "274c5d58-9da3-427c-d665-dca0c2fab9ba"
   },
   "outputs": [],
   "source": [
    "# Visualizing Arborio rice type\n",
    "rice_type = 'Arborio'\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "for i in range(1, 10, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    img = load_img(folder_path + \"train/\" + rice_type + \"/\" +\n",
    "                  os.listdir(folder_path + \"train/\" + rice_type)[i], target_size = (picture_size, picture_size))\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a269a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "1e3a269a",
    "outputId": "1ffd0d67-727b-44c3-e3c7-66dd8b74cb32"
   },
   "outputs": [],
   "source": [
    "# Visualizing Basmati rice type\n",
    "rice_type = 'Basmati'\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "for i in range(1, 10, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    img = load_img(folder_path + \"train/\" + rice_type + \"/\" +\n",
    "                  os.listdir(folder_path + \"train/\" + rice_type)[i], target_size = (picture_size, picture_size))\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d92c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "cd5d92c8",
    "outputId": "5d421adf-98f5-4585-dbbf-d92ffba3dc43"
   },
   "outputs": [],
   "source": [
    "# Visualizing Ipsala rice type\n",
    "rice_type = 'Ipsala'\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "for i in range(1, 10, 1):\n",
    "    plt.subplot(3,3,i)\n",
    "    img = load_img(folder_path + \"train/\" + rice_type + \"/\" +\n",
    "                  os.listdir(folder_path + \"train/\" + rice_type)[i], target_size = (picture_size, picture_size))\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b813d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "11b813d1",
    "outputId": "0d20ab81-8623-4039-dbaf-7db842510f45"
   },
   "outputs": [],
   "source": [
    "# Visualizing Jasmine rice type\n",
    "rice_type = 'Jasmine'\n",
    "\n",
    "plt.figure(figsize= (12, 12))\n",
    "\n",
    "for i in range(1, 10, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    img = load_img(folder_path + \"train/\" + rice_type + \"/\" +\n",
    "                  os.listdir(folder_path + \"train/\" + rice_type)[i], target_size = (picture_size, picture_size))\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d5693",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "345d5693",
    "outputId": "2256f5d5-04f6-4e8d-c205-11a76d6761b7"
   },
   "outputs": [],
   "source": [
    "# Visualizing Karacadag rice type\n",
    "rice_type = 'Karacadag'\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "for i in range(1, 10, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    img = load_img(folder_path + \"train/\" + rice_type + \"/\" +\n",
    "                  os.listdir(folder_path + \"train/\" + rice_type)[i], target_size = (picture_size, picture_size))\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359755c",
   "metadata": {
    "id": "9359755c"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "1) We have magnified images of rice on black background. The images are fairly simple and there are no features or curves other than the shape of the grain.\n",
    "\n",
    "2) Since these images are already present in various orientations, we don't need to try data augmentation on these images before training.\n",
    "\n",
    "3) On visual inspection, we can see that Basmati rice has the longest grains, followed by Jasmine.\n",
    "\n",
    "4) Karacadag has almost rounded grains.\n",
    "\n",
    "5) Jasmine rice has an evenly distributed structure, i.e, they are not too long nor too short and their ends are somewhat sharp.\n",
    "\n",
    "6) Ipsala has a cleft end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d2058",
   "metadata": {
    "id": "2b8d2058"
   },
   "source": [
    "## **Creating Train and Test Image Data Generators**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QrT0XjRJazbb",
   "metadata": {
    "id": "QrT0XjRJazbb"
   },
   "source": [
    "Let's create data loaders to pass to the neural network architectures. We will let the train, validation, and test data loaders take the images from their respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c05fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "358c05fe",
    "outputId": "13258fab-7b94-4ce2-ad60-779630343091"
   },
   "outputs": [],
   "source": [
    "batch_size  = 128\n",
    "\n",
    "datagen_train  = ImageDataGenerator()\n",
    "datagen_val = ImageDataGenerator()\n",
    "datagen_test = ImageDataGenerator()\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path + 'train/',\n",
    "                                              target_size = (picture_size, picture_size),\n",
    "                                              color_mode = \"grayscale\",\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              classes = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag'],\n",
    "                                              shuffle = True)\n",
    "\n",
    "validation_set = datagen_val.flow_from_directory(folder_path + 'validation/',\n",
    "                                              target_size = (picture_size, picture_size),\n",
    "                                              color_mode = \"grayscale\",\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              classes = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag'],\n",
    "                                              shuffle = True)\n",
    "\n",
    "test_set = datagen_test.flow_from_directory(folder_path + 'test/',\n",
    "                                              target_size = (picture_size, picture_size),\n",
    "                                              color_mode = \"grayscale\",\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              classes = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag'],\n",
    "                                              shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d9335",
   "metadata": {
    "id": "257d9335"
   },
   "source": [
    "Let's train the model next. As we observe above that the dataset is huge. It consists of about 74K images distributed into 5 classes. So we don't need to run our data set over a large number of epochs. We are choosing just 2 epochs to avoid high computational time. However, interested learners can play around with that parameter to see if you're getting better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3PjJ3HUawrsM",
   "metadata": {
    "id": "3PjJ3HUawrsM"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db0ef9",
   "metadata": {
    "id": "85db0ef9"
   },
   "source": [
    "### **Creating our Base ANN Model**\n",
    "\n",
    "Let's create an ANN model sequentially, where we will be adding the layers one after another. Unlike Convolutional Neural Networks, Artificial Neural Networks cannot have images as inputs. We need to pass tabular data to Artificial Neural Networks. Therefore we need to Flatten the images to convert it into 1-D arrays before we feed it to the Fully Connected Layers. Therefore, our first layer in the ANN while working with image data should be a 'Flatten' layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349d65b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9349d65b",
    "outputId": "9ac71e3e-00ad-48a8-bf98-b43e5be31206"
   },
   "outputs": [],
   "source": [
    "annmodel_1 = Sequential([\n",
    "\n",
    "    # Adding Flatten layer\n",
    "    Flatten(input_shape = (48, 48, 1)),\n",
    "\n",
    "    # Dense or Fully Connected Layers\n",
    "    Dense(512, activation = 'relu'),\n",
    "    Dense(256, activation = 'relu'),\n",
    "\n",
    "    # Classifier\n",
    "    Dense(5, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "annmodel_1.compile(optimizer = 'adam', loss = 'categorical_crossentropy',  metrics = ['accuracy'])\n",
    "\n",
    "# Printing out the model summary\n",
    "annmodel_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a0e41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "535a0e41",
    "outputId": "39b110f1-8e7d-47e9-ce2d-c4e0f5e6bb1c"
   },
   "outputs": [],
   "source": [
    "history = annmodel_1.fit(train_set, validation_data = validation_set, epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82777944",
   "metadata": {
    "id": "82777944"
   },
   "source": [
    "#### **Let's evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a1971",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "250a1971",
    "outputId": "316f3072-9012-443c-c575-769494a5884e"
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = next(test_set)\n",
    "accuracy = annmodel_1.evaluate(test_images, test_labels, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a332a",
   "metadata": {
    "id": "f29a332a"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- The ANN or fully connected model has given an accuracy of about 95% on the training data and about 87% on the test data. The reason an ANN model is performing so well over image data might be all the images have the subject, i.e, the rice grain, exactly in their center. So, the local spatiality is not becoming a huge issue here.\n",
    "- Moreover, the images are not too complex and they have these grains over a black background, just as in the MNIST datasets. Hence, an ANN actually performs well in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc26211",
   "metadata": {
    "id": "9dc26211"
   },
   "source": [
    "### **Creating our Base CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a567c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48a567c4",
    "outputId": "049be2e9-a04d-4886-ca77-d7d20c936045"
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# First Convolutional Block\n",
    "model1.add(Conv2D(32, (3, 3), input_shape = (48, 48, 1), padding = 'same'))\n",
    "model1.add(LeakyReLU(0.1))\n",
    "model1.add(MaxPooling2D(2, 2))\n",
    "\n",
    "# Second Convolutional Block\n",
    "model1.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model1.add(LeakyReLU(0.1))\n",
    "model1.add(MaxPooling2D(2, 2))\n",
    "\n",
    "# Third Convolutional Block\n",
    "model1.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model1.add(LeakyReLU(0.1))\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "\n",
    "# Fourth Convolutional Block\n",
    "model1.add(Conv2D(256, (3, 3), padding = 'same'))\n",
    "model1.add(LeakyReLU(0.1))\n",
    "model1.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Fully Connected Block\n",
    "model1.add(Dense(512))\n",
    "model1.add(LeakyReLU(0.1))\n",
    "\n",
    "# Classifier\n",
    "model1.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "adam = optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76861032",
   "metadata": {
    "id": "76861032"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model1.compile(loss ='binary_crossentropy', optimizer = adam , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa15bb19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa15bb19",
    "outputId": "83f7f2e4-91a5-4025-f05d-03021ff808a3"
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "history1 = model1.fit(train_set, validation_data = validation_set, epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8370b9",
   "metadata": {
    "id": "df8370b9"
   },
   "source": [
    "#### **Let's evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7796e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7796e6",
    "outputId": "043489e6-fa8f-449c-c08d-0ec3f8826652"
   },
   "outputs": [],
   "source": [
    "accuracy = model1.evaluate(test_images, test_labels, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69755a3",
   "metadata": {
    "id": "b69755a3"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "- The test accuracy has improved significantly. However, there is a huge difference in the current and the previous model's computation times. You can see, that when we are evaluating our model on the test set, the ANN model took about 40 ms/step. The CNN model took 106 ms/step. These inference times may seem small, but they become very evident on an industrial scale.\n",
    "- Let's see if we can move towards a smaller model that has a similar test accuracy and the smaller size will help to reduce the computation time and make it more suitable to be user in production easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e259b6",
   "metadata": {
    "id": "82e259b6"
   },
   "source": [
    "### **Creating a Smaller Model**\n",
    "\n",
    "A simple design thinking we can do here is, to create a smaller model, we have to simply bring down the number of parameters. Let's reduce the number of Convolutional blocks from 4 to 3. And we will also add Dropout layers with each Convolutional block. These dropout layers shall have 0.2 as their inclusion parameter, meaning that only 20 percent of the parameters will be retained and the rest shall be dropped. These should bring down the model size and also the inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfca78c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdfca78c",
    "outputId": "1b3dfbc9-d72a-4166-882b-d68bb710ea68",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating sequential model\n",
    "model2 = Sequential()\n",
    "\n",
    "# First Convolutional Block\n",
    "model2.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\", input_shape=(48, 48, 1)))\n",
    "model2.add(MaxPooling2D(pool_size = 2))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# Second Convolutional Block\n",
    "model2.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size = 2))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# Third Convolutional Block\n",
    "model2.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size = 2))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# Fully Connected Layers\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(512, activation = \"relu\"))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "# Classifier\n",
    "model2.add(Dense(5, activation = \"softmax\")) # 5 represents output layer neurons\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84fc6c",
   "metadata": {
    "id": "cf84fc6c"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model2.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa99fb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fa99fb3",
    "outputId": "35077bef-1640-4cd6-ef01-56399bc9092d"
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "history2 = model2.fit(train_set, validation_data = validation_set, epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99357a78",
   "metadata": {
    "id": "99357a78"
   },
   "source": [
    "#### **Let's test the model on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8c1b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24c8c1b1",
    "outputId": "9bb9cd09-327e-4a0d-dbb3-a12daa491221"
   },
   "outputs": [],
   "source": [
    "accuracy = model2.evaluate(test_images, test_labels, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf58aab",
   "metadata": {
    "id": "3cf58aab"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- The final training accuracy is close to 92 percent, however, our testing accuracy is better than all the other models. This means our Dropout Layers are not letting the model overfit the training data.\n",
    "\n",
    "- As predicted our inference time on our test set has also come down to 55 ms/step, which is what we were looking for primarily. Therefore, we are moving ahead with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w-EU_nLOlyg8",
   "metadata": {
    "id": "w-EU_nLOlyg8"
   },
   "source": [
    "### **Plotting Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9RoCY_9Nlrgj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "9RoCY_9Nlrgj",
    "outputId": "468f163b-7b0f-485c-9b82-0812d694e367"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model2.predict(test_images)\n",
    "pred = np.argmax(pred, axis = 1)\n",
    "y_true = np.argmax(test_labels, axis = 1)\n",
    "\n",
    "# Plotting the heatmap using confusion matrix\n",
    "cm = confusion_matrix(y_true, pred)\n",
    "plt.figure(figsize = (8, 5))\n",
    "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag'], yticklabels = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vvp_791Doeh-",
   "metadata": {
    "id": "Vvp_791Doeh-"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- As observed from the confusion matrix, there are very few misclassification by the model.\n",
    "\n",
    "- One instance of Basmati is wrongly classified as Jasmine. A Possible reason could be that both of these rice types have longer grains.\n",
    "\n",
    "- Two instances of Karacadag are wrongly classified as Arborio. A Possible reason is, that both of them have rounded grains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869861bf",
   "metadata": {
    "id": "869861bf"
   },
   "source": [
    "## **Conclusion**\n",
    "\n",
    "- This problem was to to find the most efficient Deep Learning architecture that can classify these magnified images of rice grains into their classes.\n",
    "- By efficiency, we are not only talking about accuracy. We are also talking about computation time because when this model will be implemented in the real world, we would expect it to be super fast, besides being super accurate.\n",
    "- We visualized the five types of rice. From manual inspection, we can state that only an expert or someone who has a lot of knowledge in the field of agriculture, can correctly identify all these rice types. That's because there are a lot of similarities between two or more classes. There are subtle differences that might not even be evident to someone not so familiar with these rice types beforehand.\n",
    "- The first architecture was a Fully Connected Neural Network. Although we don't expect ANNs or Fully Connected Neural Networks to perform well with image data, this model did quite well. The possible reason was that all the images had grain in their center. So, local spatiality was not an issue. But still, its test accuracy was lower in comparision to CNN models.\n",
    "- The first CNN model perfomed extremely well. But it was a huge model and naturally, we see exceptionally high computation time. This may bring down it's efficiency while being used in real world.\n",
    "\n",
    "- Therefore, we go for a smaller CNN model (less number of parameters). This model had a low computation time and had the best test accuracy among all the models. There are very few misclassification made by the model. Hence, we will pick 'model2' as the final model for rice type classification."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
